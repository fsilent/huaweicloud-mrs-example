<!---
id: 12610857
title: Flink性能测试工具Hibench使用指引
 --->

# 前提条件
1. 安装服务Flink、HDFS、Yarn、Spark2x、Kakfa 

2. 下载工具：Hibench-7.1

3. 安装集群客户端

4. 集群Yarn NodeManager节点数为3

5. 集群Kafka配置：Broker实例为3，配置项allow.everyone.if.no.acl.foun为true

6. 运行节点安装了Python3

    **本指引的代码环境**  
    **客户端安装目录：/opt/client**  
    **Hibench安装目录：/opt/Hibench-7.1**  
    **以identity为例子**  
    **MRS 321环境**  
    **Python3版本**

# 下载Hibench工具
1. 下载附件中的 HiBench-7.1.tar 文件，并解压到 /opt 目录下。  
解压命令：
```bash 
tar -xf HiBench-7.1.tar
```
2. 将 Hibench-7.1 目录下所有权限设置为777
```bash 
cd /opt
chmod 777 HiBench-7.1 -R
```

# 打包Hibench工具

注：如果直接使用打包好的HiBench工具则不需要执行此步骤。

1.下载文件，链接为：

```
https://github.com/huaweicloud/huaweicloud-mrs-example/tree/performance-tools/performance-tools/Flink
```

2.编译打包

编译命令

```
mvn clean install -Dmaven.wagon.http.ssl.insecure=true -Dmaven.wagon.http.ssl.allowall=true -Dmaven.wagon.http.ssl.ignore.validity.dates=true -rf hadoopbench/mahout/
```

打包Flink

```
tar -zcvf HiBench-7.1.tar  Flink
```

可能在编译过程中存在部分安装包无法下载的问题，需要离线下载

在mrs-tools\performance-tools\Flink\hadoopbench\sql\target 目录下添加文件

 [apache-hive-0.14.0-bin.tar.gz](hadoopbench\sql\target\apache-hive-0.14.0-bin.tar.gz) 

mrs-tools\performance-tools\Flink\hadoopbench\nutchindexing\target目录下添加文件

 [apache-nutch-1.2-bin.tar.gz](hadoopbench\nutchindexing\target\apache-nutch-1.2-bin.tar.gz) 

mrs-tools\performance-tools\Flink\hadoopbench\mahout\target目录下添加文件

 [mahout-0.9-cdh5.1.0.tar.gz](hadoopbench\mahout\target\mahout-0.9-cdh5.1.0.tar.gz)  [apache-mahout-distribution-0.11.0.tar.gz](hadoopbench\mahout\target\apache-mahout-distribution-0.11.0.tar.gz) 

3 上传 HiBench-7.1.tar 文件，并解压到 /opt 目录下。  
解压命令：

```
tar -xf HiBench-7.1.tar   
```

4将 Hibench-7.1 目录下所有权限设置为777

```
cd /opt
chmod 777 HiBench-7.1 -R
```

5转换文件格式

```
cd Hibench-7.1/
find . -type f -exec dos2unix {} \;
```

或者转换主要文本的格式

```
dos2unix bin/functions/
```

# 安装并修改客户端配置

1. 下载并安装客户端  
这里我将客户端安装在 /opt/client 目录下

2. 修改core-site.xml
```bash 
vim /opt/client/HDFS/hadoop/etc/hadoop/core-site.xml
```

在倒数第二行添加：
```
<property>
    <name>fs.hdfs.impl</name>
    <value>org.apache.hadoop.hdfs.DistributedFileSystem</value>
</property>
```
保存并退出

3. 修改hdfs-site.xml
```bash 
vim /opt/client/HDFS/hadoop/etc/hadoop/hdfs-site.xml
```
修改到 name 为 dfs.client.failover.proxy.provider.hacluster 的value：
`
org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider 
`  
完整版如下：

```
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
```

4. 替换krb5.conf：

   用客户端下的krb5.conf替换掉etc目录下的krb5.conf文件，客户端krb5.conf文件目录为/opt/hadoopclient/KrbClient/kerberos/var/krb5kdc/krb5.conf。需要将集群内所有节点的krb5.conf文件都替换。

5. 下载用户认证凭据并解压到/opt目录
```bash
登录集群Manager界面，选择“系统 > 权限 > 用户”，找到用户flinktest并下载认证凭据，解压认证凭据文件包获取到user.keytab文件，然后上传到客户端节点，例如/opt目录。
cd /opt
tar -xf flinkuser_*.tar
```

5. 修改flink-conf.yaml
```bash
source /opt/client/bigdata_env
vim /opt/client/Flink/flink/conf/flink-conf.yaml
```
修改以下值  
```
security.kerberos.login.keytab: /opt/user.keytab
security.kerberos.login.principal: flinkuser
security.ssl.enabled: false  
```
添加以下参数：  
```
classloader.resolve-order: parent-first
yarn.containers.vcores: 2
```
6. 执行generate_keystore.sh脚本
```bash
sh /opt/client/Flink/flink/bin/generate_keystore.sh
```
7. 修改hadoop.conf
```bash
vim /opt/HiBench-7.1/conf/hadoop.conf

hibench.hadoop.home     /opt/client/HDFS/hadoop
hibench.hdfs.master       hdfs://hacluster
```
8. 修改hibench.conf
```bash
vim /opt/HiBench-7.1/conf/hibench.conf
```
按需修改以下参数：  
```
# Yarn能够支持的最大Map数
hibench.default.map.parallelism             8
# 与map数保持一致 
hibench.default.shuffle.parallelism         8
```
Kafka配置部分：
```
# kafka客户端路径
hibench.streambench.kafka.home              /opt/client/Kafka/kafka
# Zookeeper地址
hibench.streambench.zkHost                  10.10.10.10:24002,10.10.10.11:24002/kafka
# kafka Broker节点地址
hibench.streambench.kafka.brokerList        10.10.10.10:21005,10.10.10.11:21005,10.10.10.12:21005
# partition数量
hibench.streambench.kafka.topicPartitions   3
# 消费模式为latest
hibench.streambench.kafka.offsetReset       latest
```
生成数据部分：
```
# 间隔时间，以毫秒为单位
hibench.streambench.datagen.intervalSpan        500
# 每个间隔期产生的记录数
hibench.streambench.datagen.recordsPerInterval  5
# 记录的固定长度
hibench.streambench.datagen.recordLength        20
# 不同线程上运行的KafkaProducer的数量
hibench.streambench.datagen.producerNumber      1
# 发送数据的总轮数 -1 为无限大
hibench.streambench.datagen.totalRounds         -1
# 将产生的总记录数 -1 为无限大
hibench.streambench.datagen.totalRecords        -1
```
9. 修改flink.conf
```bash
vim /opt/HiBench-7.1/conf/flink.conf
```

```
# flink客户端安装路径
hibench.streambench.flink.home                  /opt/client/Flink/flink/
# ip地址为flink原生界面IP
hibench.flink.master                            10.10.10.10:20026
# flink任务并发数
hibench.streambench.flink.parallelism           2
# 在低流量时的系统最大延迟
hibench.streambench.flink.bufferTimeout         10
# checkpoint间隔
hibench.streambench.flink.checkpointDuration    1000
```
10. 修改metrics_reader.sh脚本  
**Hibench7支持4种测试模型：fixwindow、wordcount、identity、repartition，修改dataGen.sh脚本时，4中测试模型都需要修改，以下以 identity 为例进行说明，其他3种测试模型是相同的修改方法。**
```bash
vim /opt/HiBench-7.1/bin/workloads/streaming/identity/common/metrics_reader.sh
```
在第32行末尾修改 kafka IP 地址  
例如：
```
CMD="${JAVA_BIN} -cp ${COMMON_JAR} com.intel.hibench.common.streaming.metrics.MetricsReader ${STREAMING_ZKADDR} ${TOPIC} ${METRICS_READER_OUTPUT_DIR} ${METRICE_READER_SAMPLE_NUM} ${METRICS_READER_THREAD_NUM} 4 10.10.10.10:21005,10.10.10.11:21005,10.10.10.12:21005"
```

# 执行脚本
1. 准备数据  

执行genSeedDataset.sh脚本
```bash
source /opt/client/bigdata_env

#进行认证
kinit flinkuser

sh /opt/HiBench-7.1/bin/workloads/streaming/identity/prepare/genSeedDataset.sh
```
执行成功结果图
![alt genSeedDataset执行成功图](http://image.huawei.com/tiny-lts/v1/images/8171896118f5fc558bf18e93d974c031_1636x626.png@900-0-90-f.png)

2. 往 kafka 实时写入数据流

执行 dagaGen.sh 脚本
```bash
source /opt/client/bigdata_env

sh /opt/HiBench-7.1/bin/workloads/streaming/identity/prepare/dataGen.sh
```
执行成功结果图
![alt dataGen执行成功图](http://image.huawei.com/tiny-lts/v1/images/36dfd3b926569eab09e48da7094a2fee_1641x808.png@900-0-90-f.png)

3. 启动flink任务消费kafka数据

执行 run.sh 脚本
```bash
source /opt/client/bigdata_env

# 启动一个yarnSession
yarn-session.sh -d

sh /opt/HiBench-7.1/bin/workloads/streaming/identity/flink/run.sh
```
执行成功结果图
![alt run执行成功图](http://image.huawei.com/tiny-lts/v1/images/b3334276bdd8afdd62777143db61b8f7_1638x502.png@900-0-90-f.png)

从yarn上进入Flink原生页面查看任务是否成功运行
![alt Flink ui 图](http://image.huawei.com/tiny-lts/v1/images/a4746bd0c6ce072f71e5ca0a0dda4547_1664x937.png@900-0-90-f.png)

4. 生成测试结果

执行 metrics_reader.sh 脚本
```bash
source /opt/client/bigdata_env

# 执行脚本并输入3步骤生成的kafkaTopic
sh /opt/HiBench-7.1/bin/workloads/streaming/identity/common/metrics_reader.sh
```
执行成功结果图
![alt Flink ui 图](http://image.huawei.com/tiny-lts/v1/images/351161a768775b2018e450a81270e5d7_1641x808.png@900-0-90-f.png)

5. 持续生成测试结果

运行loop_metrics_reader.sh脚本
```bash
source /opt/client/bigdata_env
# 每30秒生成一次测试结果
# 后面需要加入两个参数
# 1.模型名称
# 2.步骤3生成Topic
# 例如
sh /opt/HiBench-7.1/bin/workloads/streaming/loop_metrics_reader.sh identity FLINK_identity_1_5_500_1658650634634
```

6. 查看测试结果

```bash
cd /opt/HiBench-7.1/report
tail -f *.csv
```
测试结果图
![alt Flink ui 图](http://image.huawei.com/tiny-lts/v1/images/d24ef9ab85bb6dca90d39c723dbf9ff2_1567x179.png@900-0-90-f.png)